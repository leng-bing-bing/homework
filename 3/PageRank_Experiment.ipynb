{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PageRank 实验"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 1., 0., 0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0., 0., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "def to_matrix(filename, n):\n",
    "    \"\"\"Return the n x n adjacency matrix described by datafile.\n",
    "\n",
    "    Parameters:\n",
    "        datafile (str): The name of a .txt file describing a directed graph.\n",
    "        Lines describing edges should have the form '<from node>\\t<to node>\\n'.\n",
    "        The file may also include comments.\n",
    "        n (int): The number of nodes in the graph described by datafile\n",
    "\n",
    "    Returns:\n",
    "        An adjacency matrix (ndarray).\n",
    "    \"\"\"\n",
    "    with open(filename, 'r') as f:\n",
    "        martix = np.zeros((n,n))\n",
    "        for line in f:\n",
    "            line = line.strip().split()\n",
    "            martix[int(line[0])][int(line[1])] = 1\n",
    "    return martix\n",
    "\n",
    "to_matrix('./matrix.txt',8)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.   , 1.   , 0.125, 0.333, 0.333, 0.5  , 1.   , 1.   ],\n",
       "       [0.   , 0.   , 0.125, 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
       "       [0.   , 0.   , 0.125, 0.333, 0.   , 0.   , 0.   , 0.   ],\n",
       "       [0.   , 0.   , 0.125, 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
       "       [0.   , 0.   , 0.125, 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
       "       [0.   , 0.   , 0.125, 0.   , 0.333, 0.   , 0.   , 0.   ],\n",
       "       [0.   , 0.   , 0.125, 0.333, 0.333, 0.5  , 0.   , 0.   ],\n",
       "       [1.   , 0.   , 0.125, 0.   , 0.   , 0.   , 0.   , 0.   ]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([[ 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "[ 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "[ 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "[ 1, 0, 1, 0, 0, 0, 1, 0],\n",
    "[ 1, 0, 0, 0, 0, 1, 1, 0],\n",
    "[ 1, 0, 0, 0, 0, 0, 1, 0],\n",
    "[ 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "[ 1, 0, 0, 0, 0, 0, 0, 0]])\n",
    "def calculateK(A,N):\n",
    "    \"\"\"Compute the matrix K as described in the lab.\n",
    "\n",
    "    Parameters:\n",
    "        A (ndarray): adjacency matrix of a gragh\n",
    "        N (int): the number of nodes in the graph\n",
    "\n",
    "    Returns:\n",
    "        K (ndarray)\n",
    "    \"\"\"\n",
    "    D = np.zeros((N, N))\n",
    "    K = np.zeros((N, N))\n",
    "    for n in range(N):\n",
    "        D[n][n] = round(1/(A[n][0]+A[n][1]+A[n][2]+A[n][3]+A[n][4]+A[n][5]+A[n][6]+A[n][7]),3)\n",
    "    K = np.dot(D,A)\n",
    "    return K.T\n",
    "calculateK(A, len(A))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.125  ]\n",
      " [0.125  ]\n",
      " [0.86875]\n",
      " [0.3375 ]\n",
      " [0.3375 ]\n",
      " [0.23125]\n",
      " [0.125  ]\n",
      " [0.125  ]]\n",
      "[[0.125  ]\n",
      " [0.125  ]\n",
      " [0.01875]\n",
      " [0.3375 ]\n",
      " [0.3375 ]\n",
      " [0.23125]\n",
      " [0.125  ]\n",
      " [0.125  ]]\n"
     ]
    }
   ],
   "source": [
    "def iter_solve(adj, max_iter, d =0.85, tol = 1e-5):\n",
    "    \"\"\"Return the page ranks of the network described by 'adj'.\n",
    "    Iterate through the PageRank algorithm until the error is less than 'tol'.\n",
    "\n",
    "    Parameters:\n",
    "        adj (ndarray): The adjacency matrix of a directed graph.\n",
    "        max_iter (int): the Maximum number of iterations.\n",
    "        d (float): The damping factor, a float between 0 and 1.\n",
    "        tol (float): Stop iterating when the change in approximations to\n",
    "        the solution is less than 'tol'.\n",
    "\n",
    "    Returns:\n",
    "        The approximation to the steady state.\n",
    "    \"\"\"\n",
    "    R0 = np.ones((len(adj), 1))*(1 / len(adj))\n",
    "    Rt = np.add(d * np.dot(adj, R0), ((1 - d) / len(adj)) * np.ones((len(adj), 1)))\n",
    "    for i in range(max_iter):\n",
    "        if abs(R0[0] - Rt[0]) < tol:\n",
    "            break;\n",
    "        Rt = np.add(d * np.dot(adj, R0) ,((1 - d) / len(adj)) * np.ones((len(adj), 1)))\n",
    "        R0 = Rt \n",
    "\n",
    "    return Rt\n",
    "\n",
    "print(iter_solve(A, 100))\n",
    "print(iter_solve(to_matrix('./matrix.txt',8), 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------best to worst-----------------\n",
      "Louisville\n",
      "VA Commonwealth\n",
      "Syracuse\n",
      "Butler\n",
      "Duke\n",
      "St Louis\n",
      "Indiana\n",
      "Mississippi\n",
      "Pittsburgh\n",
      "Missouri\n",
      "Florida\n",
      "Memphis\n",
      "Notre Dame\n",
      "Temple\n",
      "Charlotte\n",
      "Ohio St\n",
      "Georgetown\n",
      "Michigan\n",
      "Kansas\n",
      "Cincinnati\n",
      "Michigan St\n",
      "Arizona\n",
      "Minnesota\n",
      "Creighton\n",
      "Akron\n",
      "New Mexico\n",
      "Massachusetts\n",
      "Marquette\n",
      "Oregon\n",
      "UCLA\n",
      "La Salle\n",
      "Wichita St\n",
      "Gonzaga\n",
      "NC State\n",
      "Arizona St\n",
      "Virginia\n",
      "Robert Morris\n",
      "Bucknell\n",
      "UNLV\n",
      "Oklahoma St\n",
      "Ohio\n",
      "Miami FL\n",
      "Kentucky\n",
      "Illinois\n",
      "Southern Miss\n",
      "Wisconsin\n",
      "Maryland\n",
      "Middle Tenn St\n",
      "Connecticut\n",
      "Richmond\n",
      "Albany NY\n",
      "North Carolina\n",
      "Col Charleston\n",
      "Iowa\n",
      "Iowa St\n",
      "St Mary's CA\n",
      "Kansas St\n",
      "Murray St\n",
      "Valparaiso\n",
      "Belmont\n",
      "Arkansas\n",
      "Tennessee\n",
      "E Kentucky\n",
      "Colorado St\n",
      "Colorado\n",
      "Louisiana Tech\n",
      "Xavier\n",
      "Villanova\n",
      "Bryant\n",
      "Texas A&M\n",
      "LSU\n",
      "San Diego St\n",
      "Illinois St\n",
      "UCF\n",
      "Loyola MD\n",
      "Dayton\n",
      "Alabama\n",
      "Boise St\n",
      "Stony Brook\n",
      "California\n",
      "Oklahoma\n",
      "NC A&T\n",
      "Tulane\n",
      "Canisius\n",
      "Norfolk St\n",
      "Kent\n",
      "BYU\n",
      "St Joseph's PA\n",
      "Houston\n",
      "Davidson\n",
      "Florida St\n",
      "Iona\n",
      "Indiana St\n",
      "Evansville\n",
      "St John's\n",
      "New Mexico St\n",
      "Vermont\n",
      "Mt St Mary's\n",
      "Bradley\n",
      "Washington\n",
      "Utah St\n",
      "N Dakota St\n",
      "Santa Clara\n",
      "Jacksonville St\n",
      "Long Island\n",
      "Georgia Tech\n",
      "Stanford\n",
      "Northeastern\n",
      "Lehigh\n",
      "Providence\n",
      "SF Austin\n",
      "Gardner Webb\n",
      "Seton Hall\n",
      "Wagner\n",
      "Fairfield\n",
      "James Madison\n",
      "Mercer\n",
      "Harvard\n",
      "Florida Intl\n",
      "FL Gulf Coast\n",
      "Detroit\n",
      "Savannah St\n",
      "Baylor\n",
      "Quinnipiac\n",
      "UC Irvine\n",
      "Tennessee St\n",
      "Wright St\n",
      "Rutgers\n",
      "Morgan St\n",
      "Nebraska\n",
      "IL Chicago\n",
      "NC Central\n",
      "W Michigan\n",
      "Air Force\n",
      "Arkansas St\n",
      "South Carolina\n",
      "Weber St\n",
      "S Dakota St\n",
      "Boston College\n",
      "Hartford\n",
      "Purdue\n",
      "Denver\n",
      "Elon\n",
      "Oregon St\n",
      "UTEP\n",
      "Rider\n",
      "Loyola-Chicago\n",
      "St Bonaventure\n",
      "Towson\n",
      "Vanderbilt\n",
      "Northwestern\n",
      "UAB\n",
      "Ark Little Rock\n",
      "SMU\n",
      "Hawaii\n",
      "Virginia Tech\n",
      "Tulsa\n",
      "Utah\n",
      "USC\n",
      "East Carolina\n",
      "Texas\n",
      "Wake Forest\n",
      "G Washington\n",
      "Niagara\n",
      "Wyoming\n",
      "Pacific\n",
      "Northern Iowa\n",
      "W Illinois\n",
      "Washington St\n",
      "George Mason\n",
      "Princeton\n",
      "Ga Southern\n",
      "S Illinois\n",
      "Cal Poly SLO\n",
      "Montana\n",
      "Central Conn\n",
      "Georgia\n",
      "CS Northridge\n",
      "South Florida\n",
      "W Kentucky\n",
      "Lafayette\n",
      "Southern Univ\n",
      "Delaware\n",
      "Cornell\n",
      "UNC Asheville\n",
      "Hampton\n",
      "Toledo\n",
      "Charleston So\n",
      "UT Arlington\n",
      "Georgia St\n",
      "Drake\n",
      "Clemson\n",
      "Oral Roberts\n",
      "DePaul\n",
      "UC Davis\n",
      "Winthrop\n",
      "Boston Univ\n",
      "Drexel\n",
      "Nevada\n",
      "Army\n",
      "Wofford\n",
      "Holy Cross\n",
      "Northwestern LA\n",
      "Manhattan\n",
      "FL Atlantic\n",
      "Marshall\n",
      "San Francisco\n",
      "Ball St\n",
      "Oakland\n",
      "Bethune-Cookman\n",
      "SE Missouri St\n",
      "Morehead St\n",
      "Troy\n",
      "CS Fullerton\n",
      "Delaware St\n",
      "WI Green Bay\n",
      "Bowling Green\n",
      "Jacksonville\n",
      "High Point\n",
      "Long Beach St\n",
      "Youngstown St\n",
      "IPFW\n",
      "TX Pan American\n",
      "CS Sacramento\n",
      "Tennessee Tech\n",
      "South Alabama\n",
      "Columbia\n",
      "Texas Tech\n",
      "William & Mary\n",
      "Appalachian St\n",
      "TCU\n",
      "St Francis NY\n",
      "West Virginia\n",
      "E Michigan\n",
      "TX Southern\n",
      "NJIT\n",
      "Yale\n",
      "Buffalo\n",
      "C Michigan\n",
      "San Diego\n",
      "Ark Pine Bluff\n",
      "Sam Houston St\n",
      "W Carolina\n",
      "UT San Antonio\n",
      "SC Upstate\n",
      "Colgate\n",
      "E Illinois\n",
      "Marist\n",
      "Cleveland St\n",
      "Maine\n",
      "Coastal Car\n",
      "Penn St\n",
      "Brown\n",
      "UNC Wilmington\n",
      "Radford\n",
      "Lipscomb\n",
      "Utah Valley\n",
      "Montana St\n",
      "N Kentucky\n",
      "Chattanooga\n",
      "North Texas\n",
      "Northern Arizona\n",
      "Mississippi St\n",
      "ULL\n",
      "Cent Arkansas\n",
      "North Dakota\n",
      "Pepperdine\n",
      "Santa Barbara\n",
      "Sacred Heart\n",
      "Idaho\n",
      "Samford\n",
      "North Florida\n",
      "Auburn\n",
      "Campbell\n",
      "Liberty\n",
      "Texas St\n",
      "McNeese St\n",
      "American Univ\n",
      "Stetson\n",
      "Monmouth NJ\n",
      "E Washington\n",
      "ETSU\n",
      "Fresno St\n",
      "VMI\n",
      "Prairie View\n",
      "Penn\n",
      "N Colorado\n",
      "Jackson St\n",
      "San Jose St\n",
      "Loy Marymount\n",
      "Portland\n",
      "St Peter's\n",
      "Southern Utah\n",
      "Rhode Island\n",
      "Duquesne\n",
      "CS Bakersfield\n",
      "Coppin St\n",
      "NE Omaha\n",
      "Navy\n",
      "Alcorn St\n",
      "F Dickinson\n",
      "Houston Bap\n",
      "Miami OH\n",
      "Missouri St\n",
      "Alabama A&M\n",
      "Siena\n",
      "Fordham\n",
      "Seattle\n",
      "SE Louisiana\n",
      "Dartmouth\n",
      "Edwardsville\n",
      "Nicholls St\n",
      "South Dakota\n",
      "Longwood\n",
      "Hofstra\n",
      "TN Martin\n",
      "Alabama St\n",
      "Austin Peay\n",
      "WI Milwaukee\n",
      "Portland St\n",
      "New Hampshire\n",
      "Presbyterian\n",
      "Citadel\n",
      "Missouri KC\n",
      "TAM C. Christi\n",
      "Chicago St\n",
      "Idaho St\n",
      "UNC Greensboro\n",
      "Old Dominion\n",
      "Howard\n",
      "MD Baltimore Co\n",
      "Florida A&M\n",
      "St Francis PA\n",
      "Furman\n",
      "New Orleans\n",
      "S Carolina St\n",
      "MS Valley St\n",
      "Rice\n",
      "UC Riverside\n",
      "N Illinois\n",
      "IUPUI\n",
      "Lamar\n",
      "Kennesaw\n",
      "ULM\n",
      "MD E Shore\n",
      "Binghamton\n",
      "Grambling\n"
     ]
    }
   ],
   "source": [
    "def team_rank(filename='ncaa2013.csv'):\n",
    "    \"\"\"Use iter_solve() to predict the rankings of the teams in the given\n",
    "    dataset of games. The dataset should have two columns, representing\n",
    "    winning and losing teams. Each row represents a game, with the winner on\n",
    "    the left, loser on the right. Parse this data to create the adjacency\n",
    "    matrix, and feed this into the solver to predict the team ranks.\n",
    "\n",
    "    Parameters:\n",
    "        filename (str): The name of the data file.\n",
    "    Returns:\n",
    "        ranks (list): The ranks of the teams from best to worst.\n",
    "        teams (list): The names of the teams, also from best to worst.\n",
    "    \"\"\"\n",
    "    with open(filename, 'r') as f:\n",
    "        f.readline()\n",
    "        team = []\n",
    "        for line in f:\n",
    "            teams = line.strip().split(',') \n",
    "            if teams[1] not in team:\n",
    "                team.append(teams[1])    #将所有队名都提取出来\n",
    "    score = np.zeros((len(team),len(team)))  #新建一个相邻矩阵\n",
    "    \n",
    "    with open(filename, 'r') as f:\n",
    "        f.readline()\n",
    "        for line in f:\n",
    "                teams = line.strip().split(',') \n",
    "                score[team.index(teams[0])][team.index(teams[1])] = 1 #获胜的队伍和失败队伍的下标的值为1\n",
    "    y = -iter_solve(score, 100, d = 0.7)\n",
    "    print(\"--------------------best to worst-----------------\")\n",
    "    for i in range(len(y.argsort(0))):\n",
    "        print(team[int(y.argsort(0)[i])])\n",
    "team_rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
